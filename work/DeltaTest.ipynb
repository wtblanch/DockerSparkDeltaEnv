{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef3c9b1",
   "metadata": {},
   "source": [
    "# Delta Lake + MLflow Test Notebook\n",
    "This notebook tests Spark 3.5.0 with Delta Lake 3.2.0 and MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd198533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = (\n",
    "    SparkSession.builder.appName(\"DeltaTest\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    ")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Delta Table\n",
    "data = spark.range(0, 5)\n",
    "data.write.format(\"delta\").mode(\"overwrite\").save(\"/home/jovyan/work/delta-table\")\n",
    "\n",
    "# Read Delta Table\n",
    "df = spark.read.format(\"delta\").load(\"/home/jovyan/work/delta-table\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e290aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow experiment logging\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:5000\")\n",
    "mlflow.set_experiment(\"local-delta-test\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 42)\n",
    "    mlflow.log_metric(\"metric1\", 0.99)\n",
    "    print(\"âœ… Run logged:\", mlflow.get_artifact_uri())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
